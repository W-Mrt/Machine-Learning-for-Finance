{"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom tensorflow.keras.models import Sequential\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom tensorflow.keras.layers import LSTM\nfrom sklearn import linear_model\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom keras.wrappers.scikit_learn import KerasClassifier","metadata":{"tags":[],"cell_id":"c34a8738fdbe40efb95035525c28622f","source_hash":"f3e56424","execution_start":1670970591751,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":32},{"cell_type":"code","source":"from sklearn import metrics","metadata":{"tags":[],"cell_id":"722a229a89eb40a28ad24164dff7163e","source_hash":"540eb31f","execution_start":1670970593219,"execution_millis":3,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":33},{"cell_type":"code","source":"import keras\nimport keras.utils\nfrom keras import utils as np_utils","metadata":{"tags":[],"cell_id":"a8a7d574247d4b0bb06a6bab9d396218","source_hash":"cd4689f7","execution_start":1670970596655,"execution_millis":8,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":"## DATA","metadata":{"tags":[],"cell_id":"91d3d0cb27864e609d090409044cffb4","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"df = pd.read_csv(\"dummy_data.csv\")\ndf.drop(['Open', 'High', 'Low', 'Adj Close', 'Volume', 'Date'], axis=1, inplace=True)\n\n# plt.figure(figsize = (12,7))\n# plt.plot(df['Date'], df['Close'])\n# plt.grid(ls = 'dotted')","metadata":{"tags":[],"cell_id":"c49610a94ef445c69b8af858c2af7c0a","source_hash":"ab14ec1c","execution_start":1670970598330,"execution_millis":13,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":35},{"cell_type":"code","source":"df","metadata":{"tags":[],"cell_id":"570ef5cc742f4771908928f457d4d949","source_hash":"f804c160","execution_start":1670970599595,"execution_millis":30,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":36,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":1,"row_count":1763,"columns":[{"name":"Close","dtype":"float64","stats":{"unique_count":1687,"nan_count":0,"min":"22.584999084472656","max":"182.00999450683597","histogram":[{"bin_start":22.584999084472656,"bin_end":38.52749862670899,"count":434},{"bin_start":38.52749862670899,"bin_end":54.46999816894532,"count":479},{"bin_start":54.46999816894532,"bin_end":70.41249771118164,"count":140},{"bin_start":70.41249771118164,"bin_end":86.35499725341798,"count":88},{"bin_start":86.35499725341798,"bin_end":102.29749679565431,"count":33},{"bin_start":102.29749679565431,"bin_end":118.23999633789063,"count":60},{"bin_start":118.23999633789063,"bin_end":134.18249588012696,"count":150},{"bin_start":134.18249588012696,"bin_end":150.1249954223633,"count":182},{"bin_start":150.1249954223633,"bin_end":166.06749496459963,"count":117},{"bin_start":166.06749496459963,"bin_end":182.00999450683597,"count":80}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"Close":"29.334999084472656","_deepnote_index_column":"0"},{"Close":"29.06999969482422","_deepnote_index_column":"1"},{"Close":"28.799999237060547","_deepnote_index_column":"2"},{"Close":"29.75749969482422","_deepnote_index_column":"3"},{"Close":"29.56999969482422","_deepnote_index_column":"4"},{"Close":"29.5575008392334","_deepnote_index_column":"5"},{"Close":"28.905000686645508","_deepnote_index_column":"6"},{"Close":"29.042499542236328","_deepnote_index_column":"7"},{"Close":"28.295000076293945","_deepnote_index_column":"8"},{"Close":"28.1200008392334","_deepnote_index_column":"9"}]},"text/plain":"           Close\n0      29.334999\n1      29.070000\n2      28.799999\n3      29.757500\n4      29.570000\n...          ...\n1758  151.070007\n1759  148.110001\n1760  144.220001\n1761  141.169998\n1762  148.029999\n\n[1763 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Close</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>29.334999</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>29.070000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28.799999</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>29.757500</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>29.570000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1758</th>\n      <td>151.070007</td>\n    </tr>\n    <tr>\n      <th>1759</th>\n      <td>148.110001</td>\n    </tr>\n    <tr>\n      <th>1760</th>\n      <td>144.220001</td>\n    </tr>\n    <tr>\n      <th>1761</th>\n      <td>141.169998</td>\n    </tr>\n    <tr>\n      <th>1762</th>\n      <td>148.029999</td>\n    </tr>\n  </tbody>\n</table>\n<p>1763 rows Ã— 1 columns</p>\n</div>"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"tf.random.set_seed(7)\ndataset = df.values\ndataset = dataset.astype('float32')","metadata":{"tags":[],"cell_id":"a97209dd374747368e2efd9172d04846","source_hash":"1014e2a7","execution_start":1670970603643,"execution_millis":172,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":"## Normalization","metadata":{"tags":[],"cell_id":"4faef447448b4cc598098200f5aacec6","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"# normalizing the dataset\nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)\ndataset","metadata":{"tags":[],"cell_id":"40e9b1efdeed4d5db18a6a4318f56e7e","source_hash":"5cb5501f","execution_start":1670970605254,"execution_millis":9,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":38,"data":{"text/plain":"array([[0.04233965],\n       [0.04067743],\n       [0.03898384],\n       ...,\n       [0.7629607 ],\n       [0.74382937],\n       [0.78685904]], dtype=float32)"},"metadata":{}}],"execution_count":38},{"cell_type":"markdown","source":"## Train/Test Sets","metadata":{"tags":[],"cell_id":"cee02f080b224578bdf8a0b4c119a0e2","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"train_size = int(len(dataset) * 0.7)\ntest_size = len(dataset) - train_size\ntrain, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\nprint(\"Train Size:\", len(train), \"\\nTest Size:\", len(test))","metadata":{"tags":[],"cell_id":"b6d7b6334e1a443b9c073b78eaf21e9d","source_hash":"b8bc3eb0","execution_start":1670970606713,"execution_millis":8,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Train Size: 1234 \nTest Size: 529\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"#building the dataset based on the number of previous days we are considering\ndef create_dataset(dataset, look_back=1):\n\tdataX, dataY = [], []\n\tfor i in range(len(dataset)-look_back-1):\n\t\ta = dataset[i:(i+look_back), 0]\n\t\tdataX.append(a)\n\t\tdataY.append(dataset[i + look_back, 0])\n\treturn np.array(dataX), np.array(dataY)","metadata":{"tags":[],"cell_id":"6b5d58b2e60a4bf68b03af44c9338efd","source_hash":"4618b2c7","execution_start":1670970612627,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":40},{"cell_type":"code","source":"look_back = 4    #number of days from today we are looking back into past","metadata":{"tags":[],"cell_id":"12099924abd84eb9a61b99c0e80a65e1","source_hash":"82c2545a","execution_start":1670970616975,"execution_millis":14,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# reshape into X=t and Y=t+1\ntrain_X, train_Y = create_dataset(train, look_back)\ntest_X, test_Y = create_dataset(test, look_back)","metadata":{"tags":[],"cell_id":"47d237d847544766be8b0944ed4c7ba2","source_hash":"af92a885","execution_start":1670970621293,"execution_millis":11,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":42},{"cell_type":"code","source":"# reshape input to be [samples, time steps, features]\ntrain_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\ntest_X =  np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))","metadata":{"tags":[],"cell_id":"a01f0c8c96084bfa9381bfaec7e28c13","source_hash":"2e7ab577","execution_start":1670970623848,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":43},{"cell_type":"code","source":"train_X","metadata":{"tags":[],"cell_id":"a2a234571be24c6aabb524bf2282030b","source_hash":"d813eb10","execution_start":1670970625676,"execution_millis":21,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":44,"data":{"text/plain":"array([[[0.04233965, 0.04067743, 0.03898384, 0.04498981]],\n\n       [[0.04067743, 0.03898384, 0.04498981, 0.04381371]],\n\n       [[0.03898384, 0.04498981, 0.04381371, 0.04373531]],\n\n       ...,\n\n       [[0.61850405, 0.6154932 , 0.6048926 , 0.58582413]],\n\n       [[0.6154932 , 0.6048926 , 0.58582413, 0.5954211 ]],\n\n       [[0.6048926 , 0.58582413, 0.5954211 , 0.5914067 ]]], dtype=float32)"},"metadata":{}}],"execution_count":44},{"cell_type":"markdown","source":"## LSTM Model","metadata":{"tags":[],"cell_id":"292dfb0ee1d24d698684eeee9d3df1de","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"# create and fit the LSTM network\nmodel = Sequential()\nmodel.add(LSTM(4, input_shape=(1, look_back)))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')","metadata":{"tags":[],"cell_id":"4122c8bd30304006b904c2aeaa867b55","source_hash":"8eb28213","execution_start":1670970628601,"execution_millis":693,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":45},{"cell_type":"markdown","source":"## Training the Model","metadata":{"tags":[],"cell_id":"28f38063f2bb4e03bffc94c244d2d2fb","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"model.fit(train_X, train_Y, epochs=10, batch_size=1, verbose=2) #epchs=10 just to see if it works or not","metadata":{"tags":[],"cell_id":"b18ef1fb7b684a9b914a45b422031b1b","source_hash":"a20d066a","execution_start":1670956390983,"execution_millis":29133,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Epoch 1/10\n1229/1229 - 4s - loss: 0.0041 - 4s/epoch - 3ms/step\nEpoch 2/10\n1229/1229 - 3s - loss: 1.0151e-04 - 3s/epoch - 2ms/step\nEpoch 3/10\n1229/1229 - 3s - loss: 9.3950e-05 - 3s/epoch - 2ms/step\nEpoch 4/10\n1229/1229 - 3s - loss: 9.8440e-05 - 3s/epoch - 2ms/step\nEpoch 5/10\n1229/1229 - 3s - loss: 9.5926e-05 - 3s/epoch - 2ms/step\nEpoch 6/10\n1229/1229 - 3s - loss: 9.8863e-05 - 3s/epoch - 2ms/step\nEpoch 7/10\n1229/1229 - 3s - loss: 9.2906e-05 - 3s/epoch - 2ms/step\nEpoch 8/10\n1229/1229 - 3s - loss: 9.5691e-05 - 3s/epoch - 2ms/step\nEpoch 9/10\n1229/1229 - 3s - loss: 9.2624e-05 - 3s/epoch - 2ms/step\nEpoch 10/10\n1229/1229 - 3s - loss: 9.3982e-05 - 3s/epoch - 2ms/step\n","output_type":"stream"},{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"<keras.callbacks.History at 0x7f12243a8430>"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"## Prediction on Test Set","metadata":{"tags":[],"cell_id":"7e30be834988469593cc9fc65f2469ef","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"# make predictions\ntrain_Predict = model.predict(train_X)\ntest_Predict = model.predict(test_X)\n\n# invert predictions\ntrain_Predict = scaler.inverse_transform(train_Predict)\ntrain_Y = scaler.inverse_transform([train_Y])\ntest_Predict = scaler.inverse_transform(test_Predict)\ntest_Y = scaler.inverse_transform([test_Y])\n\n# calculate root mean squared error\ntrain_Score = np.sqrt(mean_squared_error(train_Y[0], train_Predict[:,0]))\nprint('Train Score: %.2f RMSE' % (train_Score))\ntest_Score = np.sqrt(mean_squared_error(test_Y[0], test_Predict[:,0]))\nprint('Test Score: %.2f RMSE' % (test_Score))","metadata":{"tags":[],"cell_id":"6fcaced9ecad471eb8a0e80ba524f04b","source_hash":"41bb406b","execution_start":1670947337923,"execution_millis":813,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"39/39 [==============================] - 1s 1ms/step\n17/17 [==============================] - 0s 1ms/step\nTrain Score: 1.62 RMSE\nTest Score: 9.73 RMSE\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## Tuning the Hyper Paramters of the Model","metadata":{"tags":[],"cell_id":"2861a0d11f3e471986b49f0a2269c553","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"## RandomizedSearch","metadata":{"tags":[],"cell_id":"568d7d955e164778be51540f8c87f2b2","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"epochs=10 # number of epochs\nLSTM_units=4 # number of lstm units\n# num_samples=1 # number of samples \nlook_back=4 # time_steps\n# num_features_2_lstm= train_X.shape[1] # numer of features\ndropout_rate=0 #0.2 is a good value # Regularization\nrecurrent_dropout=0\nverbose=2\ntscv = 4   #k-fold corss validation paramter\n# scoring_lstm = 'mean_squared_error'  \n\n# hyperparameters\n\nparam_random_search = {'batch_size':[10,100], 'epochs':[1, 10]}\n\n# param_random_search ={'look_back':[1, 5 , 10],\n#                       'LSTM_units':[1, 5, 10],\n#                       'dropout_rate':[0, 0.2, 0.4]}","metadata":{"tags":[],"cell_id":"225a8d948c354ddabd651e43a4b35fba","source_hash":"4db2cbcd","execution_start":1670972794439,"execution_millis":0,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":75},{"cell_type":"code","source":"# def create_LSTM(epochs=1,LSTM_units=1,num_samples=1,look_back=4,num_features=None,dropout_rate=0,recurrent_dropout=0,verbose=0):\n#     model=Sequential()\n#     model.add(LSTM(units=LSTM_units,\n#                    input_shape=(1, look_back), \n#                 #    batch_input_shape=(num_samples, look_back, num_features), \n#                 #    stateful=True, \n#                    recurrent_dropout=recurrent_dropout)) \n#     model.add(Dropout(dropout_rate))\n#     model.add(Dense(1, activation='sigmoid', kernel_initializer=keras.initializers.he_normal(seed=1)))\n#     model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n#     return model\n\n\n\ndef create_LSTM(epochs=1,LSTM_units=1,num_samples=1,look_back=4,num_features=None,dropout_rate=0,recurrent_dropout=0,verbose=0):\n# create and fit the LSTM network\n    model = Sequential()\n    model.add(LSTM(4, input_shape=(1, look_back)))\n    model.add(Dense(1))\n    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n    return(model)\n\n\n\n# Wrapping the Classifier\nwrapped_lstm =KerasClassifier(build_fn=create_LSTM, \n                           epochs=epochs,\n                           LSTM_units=LSTM_units, \n                        #    num_samples=num_samples, \n                           look_back=look_back, \n                        #    num_features=num_features_2_lstm, \n                           dropout_rate=dropout_rate,\n                           recurrent_dropout=recurrent_dropout,\n                           verbose=verbose)\n\n# Create randomized search \nrandom_search =RandomizedSearchCV(wrapped_lstm, \n                                 param_random_search, \n                                 n_iter=10, \n                                 random_state=1, \n                                 cv=tscv, \n                                 verbose=1, \n                                 n_jobs=-1, \n                                #  scoring=scoring_lstm, \n                                #  refit=scoring_lstm, \n                                 return_train_score=True,\n                                 error_score='raise')\n\n\n# Fit randomized search\n\nrandom_search_fit = random_search.fit(train_X, train_Y)\n\n#saving the randomizedsearch result\npd.DataFrame(random_search_fit.cv_results_).to_csv(\"random_search_res.csv\")","metadata":{"tags":[],"cell_id":"215edb31e3f04369ba729ce071f1f1c9","source_hash":"33c33261","output_cleared":false,"execution_start":1670972796720,"execution_millis":151595,"is_output_hidden":false,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_76/2337500459.py:26: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n  wrapped_lstm =KerasClassifier(build_fn=create_LSTM,\nFitting 4 folds for each of 4 candidates, totalling 16 fits\n93/93 - 4s - loss: 259934.3906 - accuracy: 0.0011 - 4s/epoch - 46ms/step\n31/31 - 1s - loss: 0.0314 - accuracy: 0.9968 - 1s/epoch - 35ms/step\n93/93 - 0s - loss: 259804.6094 - accuracy: 0.0011 - 388ms/epoch - 4ms/step\n93/93 - 4s - loss: 262332.8438 - accuracy: 0.0011 - 4s/epoch - 47ms/step\n31/31 - 1s - loss: 102252.6797 - accuracy: 0.0000e+00 - 1s/epoch - 42ms/step\n93/93 - 0s - loss: 262221.3438 - accuracy: 0.0011 - 314ms/epoch - 3ms/step\n93/93 - 4s - loss: 255675.9219 - accuracy: 0.0011 - 4s/epoch - 48ms/step\n31/31 - 4s - loss: 317483.0938 - accuracy: 0.0000e+00 - 4s/epoch - 127ms/step\n93/93 - 0s - loss: 255544.9844 - accuracy: 0.0011 - 404ms/epoch - 4ms/step\n93/93 - 5s - loss: 252441.0000 - accuracy: 0.0011 - 5s/epoch - 53ms/step\n31/31 - 1s - loss: 754271.5625 - accuracy: 0.0000e+00 - 1s/epoch - 41ms/step\n93/93 - 0s - loss: 252366.2188 - accuracy: 0.0011 - 394ms/epoch - 4ms/step\nEpoch 1/10\n93/93 - 5s - loss: 259955.5156 - accuracy: 0.0011 - 5s/epoch - 51ms/step\nEpoch 2/10\n93/93 - 1s - loss: 259734.5781 - accuracy: 0.0011 - 582ms/epoch - 6ms/step\nEpoch 3/10\n93/93 - 1s - loss: 259444.8281 - accuracy: 0.0011 - 597ms/epoch - 6ms/step\nEpoch 4/10\n93/93 - 1s - loss: 259059.6719 - accuracy: 0.0011 - 521ms/epoch - 6ms/step\nEpoch 5/10\n93/93 - 1s - loss: 258579.6250 - accuracy: 0.0011 - 525ms/epoch - 6ms/step\nEpoch 6/10\n93/93 - 1s - loss: 258009.4531 - accuracy: 0.0011 - 583ms/epoch - 6ms/step\nEpoch 7/10\n93/93 - 1s - loss: 257408.6094 - accuracy: 0.0011 - 597ms/epoch - 6ms/step\nEpoch 8/10\n93/93 - 1s - loss: 256827.0938 - accuracy: 0.0011 - 519ms/epoch - 6ms/step\nEpoch 9/10\n93/93 - 1s - loss: 256276.3594 - accuracy: 0.0011 - 579ms/epoch - 6ms/step\nEpoch 10/10\n93/93 - 1s - loss: 255748.3906 - accuracy: 0.0011 - 585ms/epoch - 6ms/step\n31/31 - 1s - loss: 14.9233 - accuracy: 0.0032 - 1s/epoch - 35ms/step\n93/93 - 0s - loss: 255488.0625 - accuracy: 0.0011 - 387ms/epoch - 4ms/step\nEpoch 1/10\n93/93 - 4s - loss: 262307.3125 - accuracy: 0.0011 - 4s/epoch - 46ms/step\nEpoch 2/10\n93/93 - 1s - loss: 262048.9844 - accuracy: 0.0011 - 595ms/epoch - 6ms/step\nEpoch 3/10\n93/93 - 1s - loss: 261654.7344 - accuracy: 0.0000e+00 - 508ms/epoch - 5ms/step\nEpoch 4/10\n93/93 - 1s - loss: 261156.9844 - accuracy: 0.0011 - 589ms/epoch - 6ms/step\nEpoch 5/10\n93/93 - 1s - loss: 260614.3750 - accuracy: 0.0011 - 511ms/epoch - 5ms/step\nEpoch 6/10\n93/93 - 1s - loss: 260060.3906 - accuracy: 0.0011 - 583ms/epoch - 6ms/step\nEpoch 7/10\n93/93 - 1s - loss: 259518.2812 - accuracy: 0.0011 - 590ms/epoch - 6ms/step\nEpoch 8/10\n93/93 - 1s - loss: 258993.7188 - accuracy: 0.0011 - 518ms/epoch - 6ms/step\nEpoch 9/10\n93/93 - 1s - loss: 258487.7344 - accuracy: 0.0011 - 581ms/epoch - 6ms/step\nEpoch 10/10\n93/93 - 1s - loss: 258001.9375 - accuracy: 0.0011 - 514ms/epoch - 6ms/step\n31/31 - 1s - loss: 99410.5703 - accuracy: 0.0000e+00 - 1s/epoch - 35ms/step\n93/93 - 0s - loss: 257759.5625 - accuracy: 0.0011 - 334ms/epoch - 4ms/step\nEpoch 1/10\n93/93 - 5s - loss: 255836.1719 - accuracy: 0.0011 - 5s/epoch - 50ms/step\nEpoch 2/10\n93/93 - 1s - loss: 255700.2969 - accuracy: 0.0011 - 517ms/epoch - 6ms/step\nEpoch 3/10\n93/93 - 1s - loss: 255467.7500 - accuracy: 0.0000e+00 - 584ms/epoch - 6ms/step\nEpoch 4/10\n93/93 - 1s - loss: 255027.0781 - accuracy: 0.0011 - 521ms/epoch - 6ms/step\nEpoch 5/10\n93/93 - 1s - loss: 254457.0938 - accuracy: 0.0011 - 588ms/epoch - 6ms/step\nEpoch 6/10\n93/93 - 1s - loss: 253855.7500 - accuracy: 0.0011 - 579ms/epoch - 6ms/step\nEpoch 7/10\n93/93 - 1s - loss: 253269.1094 - accuracy: 0.0011 - 523ms/epoch - 6ms/step\nEpoch 8/10\n93/93 - 1s - loss: 252707.8594 - accuracy: 0.0011 - 582ms/epoch - 6ms/step\nEpoch 9/10\n93/93 - 1s - loss: 252173.5469 - accuracy: 0.0011 - 591ms/epoch - 6ms/step\nEpoch 10/10\n93/93 - 1s - loss: 251664.4219 - accuracy: 0.0011 - 504ms/epoch - 5ms/step\n31/31 - 1s - loss: 312314.6250 - accuracy: 0.0000e+00 - 1s/epoch - 33ms/step\n93/93 - 0s - loss: 251412.1875 - accuracy: 0.0011 - 388ms/epoch - 4ms/step\nEpoch 1/10\n93/93 - 5s - loss: 252412.3438 - accuracy: 0.0011 - 5s/epoch - 52ms/step\nEpoch 2/10\n93/93 - 1s - loss: 252182.9062 - accuracy: 0.0011 - 586ms/epoch - 6ms/step\nEpoch 3/10\n93/93 - 1s - loss: 251843.7969 - accuracy: 0.0011 - 518ms/epoch - 6ms/step\nEpoch 4/10\n93/93 - 1s - loss: 251387.0469 - accuracy: 0.0011 - 572ms/epoch - 6ms/step\nEpoch 5/10\n93/93 - 1s - loss: 250850.1875 - accuracy: 0.0011 - 603ms/epoch - 6ms/step\nEpoch 6/10\n93/93 - 1s - loss: 250276.2031 - accuracy: 0.0011 - 601ms/epoch - 6ms/step\nEpoch 7/10\n93/93 - 1s - loss: 249697.5938 - accuracy: 0.0011 - 583ms/epoch - 6ms/step\nEpoch 8/10\n93/93 - 1s - loss: 249127.9844 - accuracy: 0.0011 - 511ms/epoch - 5ms/step\nEpoch 9/10\n93/93 - 1s - loss: 248576.9062 - accuracy: 0.0011 - 594ms/epoch - 6ms/step\nEpoch 10/10\n93/93 - 1s - loss: 248044.8281 - accuracy: 0.0011 - 591ms/epoch - 6ms/step\n31/31 - 1s - loss: 743631.3125 - accuracy: 0.0000e+00 - 1s/epoch - 33ms/step\n93/93 - 0s - loss: 247780.6875 - accuracy: 0.0011 - 366ms/epoch - 4ms/step\n10/10 - 4s - loss: 260084.9688 - accuracy: 0.0011 - 4s/epoch - 382ms/step\n4/4 - 1s - loss: 0.0034 - accuracy: 0.9968 - 998ms/epoch - 249ms/step\n10/10 - 0s - loss: 260069.0938 - accuracy: 0.0011 - 80ms/epoch - 8ms/step\n10/10 - 4s - loss: 262358.4062 - accuracy: 0.0011 - 4s/epoch - 429ms/step\n4/4 - 1s - loss: 102346.0781 - accuracy: 0.0000e+00 - 1s/epoch - 302ms/step\n10/10 - 0s - loss: 262347.7188 - accuracy: 0.0011 - 90ms/epoch - 9ms/step\n10/10 - 5s - loss: 255873.3125 - accuracy: 0.0011 - 5s/epoch - 458ms/step\n4/4 - 1s - loss: 317807.4688 - accuracy: 0.0000e+00 - 1s/epoch - 273ms/step\n10/10 - 0s - loss: 255862.3750 - accuracy: 0.0011 - 34ms/epoch - 3ms/step\n10/10 - 4s - loss: 252536.9531 - accuracy: 0.0011 - 4s/epoch - 410ms/step\n4/4 - 1s - loss: 754765.3125 - accuracy: 0.0000e+00 - 1s/epoch - 326ms/step\n10/10 - 0s - loss: 252528.7969 - accuracy: 0.0011 - 87ms/epoch - 9ms/step\nEpoch 1/10\n10/10 - 4s - loss: 259994.1562 - accuracy: 0.0011 - 4s/epoch - 417ms/step\nEpoch 2/10\n10/10 - 0s - loss: 259969.2031 - accuracy: 0.0011 - 23ms/epoch - 2ms/step\nEpoch 3/10\n10/10 - 0s - loss: 259944.0312 - accuracy: 0.0011 - 91ms/epoch - 9ms/step\nEpoch 4/10\n10/10 - 0s - loss: 259918.9375 - accuracy: 0.0011 - 89ms/epoch - 9ms/step\nEpoch 5/10\n10/10 - 0s - loss: 259891.9375 - accuracy: 0.0011 - 92ms/epoch - 9ms/step\nEpoch 6/10\n10/10 - 0s - loss: 259864.6875 - accuracy: 0.0011 - 89ms/epoch - 9ms/step\nEpoch 7/10\n10/10 - 0s - loss: 259836.3750 - accuracy: 0.0011 - 28ms/epoch - 3ms/step\nEpoch 8/10\n10/10 - 0s - loss: 259806.9688 - accuracy: 0.0011 - 85ms/epoch - 8ms/step\nEpoch 9/10\n10/10 - 0s - loss: 259775.7969 - accuracy: 0.0011 - 94ms/epoch - 9ms/step\nEpoch 10/10\n10/10 - 0s - loss: 259743.5156 - accuracy: 0.0011 - 87ms/epoch - 9ms/step\n4/4 - 1s - loss: 0.0440 - accuracy: 0.9968 - 1s/epoch - 266ms/step\n10/10 - 0s - loss: 259723.7031 - accuracy: 0.0011 - 29ms/epoch - 3ms/step\nEpoch 1/10\n10/10 - 4s - loss: 262462.2188 - accuracy: 0.0011 - 4s/epoch - 380ms/step\nEpoch 2/10\n10/10 - 0s - loss: 262441.5000 - accuracy: 0.0011 - 82ms/epoch - 8ms/step\nEpoch 3/10\n10/10 - 0s - loss: 262421.1875 - accuracy: 0.0011 - 88ms/epoch - 9ms/step\nEpoch 4/10\n10/10 - 0s - loss: 262401.4688 - accuracy: 0.0011 - 91ms/epoch - 9ms/step\nEpoch 5/10\n10/10 - 0s - loss: 262381.7188 - accuracy: 0.0011 - 88ms/epoch - 9ms/step\nEpoch 6/10\n10/10 - 0s - loss: 262361.6562 - accuracy: 0.0011 - 24ms/epoch - 2ms/step\nEpoch 7/10\n10/10 - 0s - loss: 262340.7188 - accuracy: 0.0011 - 96ms/epoch - 10ms/step\nEpoch 8/10\n10/10 - 0s - loss: 262319.4062 - accuracy: 0.0011 - 86ms/epoch - 9ms/step\nEpoch 9/10\n10/10 - 0s - loss: 262296.7500 - accuracy: 0.0011 - 92ms/epoch - 9ms/step\nEpoch 10/10\n10/10 - 0s - loss: 262273.3438 - accuracy: 0.0011 - 25ms/epoch - 2ms/step\n4/4 - 1s - loss: 102263.7031 - accuracy: 0.0000e+00 - 932ms/epoch - 233ms/step\n10/10 - 0s - loss: 262259.0000 - accuracy: 0.0011 - 32ms/epoch - 3ms/step\nEpoch 1/10\n10/10 - 4s - loss: 255866.1719 - accuracy: 0.0011 - 4s/epoch - 402ms/step\nEpoch 2/10\n10/10 - 0s - loss: 255848.4688 - accuracy: 0.0011 - 105ms/epoch - 11ms/step\nEpoch 3/10\n10/10 - 0s - loss: 255830.8750 - accuracy: 0.0011 - 80ms/epoch - 8ms/step\nEpoch 4/10\n10/10 - 0s - loss: 255813.2031 - accuracy: 0.0011 - 87ms/epoch - 9ms/step\nEpoch 5/10\n10/10 - 0s - loss: 255795.1562 - accuracy: 0.0011 - 22ms/epoch - 2ms/step\nEpoch 6/10\n10/10 - 0s - loss: 255776.4844 - accuracy: 0.0011 - 93ms/epoch - 9ms/step\nEpoch 7/10\n10/10 - 0s - loss: 255756.7344 - accuracy: 0.0011 - 87ms/epoch - 9ms/step\nEpoch 8/10\n10/10 - 0s - loss: 255736.1719 - accuracy: 0.0011 - 85ms/epoch - 9ms/step\nEpoch 9/10\n10/10 - 0s - loss: 255714.3281 - accuracy: 0.0011 - 29ms/epoch - 3ms/step\nEpoch 10/10\n10/10 - 0s - loss: 255691.3125 - accuracy: 0.0011 - 32ms/epoch - 3ms/step\n4/4 - 1s - loss: 317591.9688 - accuracy: 0.0000e+00 - 987ms/epoch - 247ms/step\n10/10 - 0s - loss: 255677.1406 - accuracy: 0.0011 - 99ms/epoch - 10ms/step\nEpoch 1/10\n10/10 - 4s - loss: 252568.3281 - accuracy: 0.0011 - 4s/epoch - 377ms/step\nEpoch 2/10\n10/10 - 0s - loss: 252552.7969 - accuracy: 0.0011 - 26ms/epoch - 3ms/step\nEpoch 3/10\n10/10 - 0s - loss: 252537.4219 - accuracy: 0.0011 - 87ms/epoch - 9ms/step\nEpoch 4/10\n10/10 - 0s - loss: 252522.4844 - accuracy: 0.0011 - 89ms/epoch - 9ms/step\nEpoch 5/10\n10/10 - 0s - loss: 252507.7656 - accuracy: 0.0011 - 90ms/epoch - 9ms/step\nEpoch 6/10\n10/10 - 0s - loss: 252493.1562 - accuracy: 0.0011 - 22ms/epoch - 2ms/step\nEpoch 7/10\n10/10 - 0s - loss: 252478.3750 - accuracy: 0.0011 - 24ms/epoch - 2ms/step\nEpoch 8/10\n10/10 - 0s - loss: 252463.4219 - accuracy: 0.0011 - 88ms/epoch - 9ms/step\nEpoch 9/10\n10/10 - 0s - loss: 252448.1406 - accuracy: 0.0011 - 100ms/epoch - 10ms/step\nEpoch 10/10\n10/10 - 0s - loss: 252432.3750 - accuracy: 0.0011 - 89ms/epoch - 9ms/step\n4/4 - 1s - loss: 754564.8750 - accuracy: 0.0000e+00 - 993ms/epoch - 248ms/step\n10/10 - 0s - loss: 252422.8438 - accuracy: 0.0011 - 87ms/epoch - 9ms/step\n123/123 - 5s - loss: 455095.8750 - accuracy: 8.1367e-04 - 5s/epoch - 37ms/step\n","output_type":"stream"}],"execution_count":76},{"cell_type":"code","source":"print(\"best parameters are:\", random_search_fit.best_params_)","metadata":{"tags":[],"cell_id":"4ce24c1ef382464fbc370d6daf333059","source_hash":"da3fabe9","execution_start":1670973129311,"execution_millis":2,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"best parameters are: {'epochs': 1, 'batch_size': 10}\n","output_type":"stream"}],"execution_count":77},{"cell_type":"markdown","source":"## GridSeachCV","metadata":{"tags":[],"cell_id":"73843b1ec0aa4a3cb3dbba5f80594895","source_hash":"12fc4a29","execution_start":1670874895003,"execution_millis":0,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"epochs=10 #number of epochs\nLSTM_units=4 # number of lstm units\nnum_samples=1 # number of samples\nlook_back=1\nnum_features_2_lstm=train_X.shape[1] # numer of features\ndropout_rate=0 # Regularization\nrecurrent_dropout=0\nverbose=0\ntscv = 4 #k-fold corss validation paramter\nscoring_lstm= 'accuracy' #scoring method\n\n# hyperparameter\nparam_grid_search={'batch_size':[1,10,100]}","metadata":{"tags":[],"cell_id":"0b5ac17bdb234cb0a4a815b002cafa92","source_hash":"e24e6110","execution_start":1670973155008,"execution_millis":3,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":80},{"cell_type":"code","source":"# Gridsearch\ngrid_search =GridSearchCV(estimator=wrapped_lstm, \n                           param_grid=param_grid_search,  \n                           n_jobs=-1,  \n                           cv=tscv, \n                           scoring=scoring_lstm, # accuracy\n                        #    refit=True, \n                           return_train_score=False)\n\n# # Fit model\ngrid_search_fit =grid_search.fit(train_X, train_Y, shuffle=False)\n\n#saving the gridsearch result\npd.DataFrame(grid_search_fit.cv_results_).to_csv(\"grid_search_res.csv\")","metadata":{"tags":[],"cell_id":"c5c758e1ecab4fb48212e7a697c5335d","source_hash":"a0174451","execution_start":1670973156948,"execution_millis":374416,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Epoch 1/10\n921/921 - 8s - loss: 255697.1406 - accuracy: 0.0011 - 8s/epoch - 8ms/step\nEpoch 2/10\n921/921 - 4s - loss: 251638.0781 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 3/10\n921/921 - 4s - loss: 248486.1250 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 4/10\n921/921 - 4s - loss: 245581.3438 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 5/10\n921/921 - 4s - loss: 242794.5156 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 6/10\n921/921 - 4s - loss: 240077.9688 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 7/10\n921/921 - 4s - loss: 237409.7188 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 8/10\n921/921 - 4s - loss: 234779.6250 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 9/10\n921/921 - 4s - loss: 232182.5000 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 10/10\n921/921 - 4s - loss: 229614.8750 - accuracy: 0.0011 - 4s/epoch - 4ms/step\n10/10 [==============================] - 1s 2ms/step\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 219, in __call__\n    return self._score(\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 267, in _score\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n    raise ValueError(\"{0} is not supported\".format(y_type))\nValueError: continuous is not supported\n\n  warnings.warn(\nEpoch 1/10\n922/922 - 7s - loss: 258031.2344 - accuracy: 0.0011 - 7s/epoch - 8ms/step\nEpoch 2/10\n922/922 - 4s - loss: 254008.3281 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 3/10\n922/922 - 4s - loss: 250845.4531 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 4/10\n922/922 - 4s - loss: 247925.1250 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 5/10\n922/922 - 4s - loss: 245124.2344 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 6/10\n922/922 - 4s - loss: 242394.8750 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 7/10\n922/922 - 4s - loss: 239715.5469 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 8/10\n922/922 - 4s - loss: 237075.7031 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 9/10\n922/922 - 4s - loss: 234469.5156 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 10/10\n922/922 - 4s - loss: 231893.9219 - accuracy: 0.0011 - 4s/epoch - 4ms/step\n10/10 [==============================] - 1s 9ms/step\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 219, in __call__\n    return self._score(\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 267, in _score\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n    raise ValueError(\"{0} is not supported\".format(y_type))\nValueError: continuous is not supported\n\n  warnings.warn(\nEpoch 1/10\n922/922 - 7s - loss: 252339.9844 - accuracy: 0.0011 - 7s/epoch - 8ms/step\nEpoch 2/10\n922/922 - 4s - loss: 248634.4844 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 3/10\n922/922 - 4s - loss: 245567.2188 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 4/10\n922/922 - 4s - loss: 242695.2344 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 5/10\n922/922 - 4s - loss: 239925.6094 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 6/10\n922/922 - 4s - loss: 237219.9688 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 7/10\n922/922 - 4s - loss: 234561.0938 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 8/10\n922/922 - 4s - loss: 231939.3906 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 9/10\n922/922 - 4s - loss: 229350.3438 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 10/10\n922/922 - 4s - loss: 226791.1094 - accuracy: 0.0011 - 4s/epoch - 4ms/step\n10/10 [==============================] - 1s 8ms/step\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 219, in __call__\n    return self._score(\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 267, in _score\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n    raise ValueError(\"{0} is not supported\".format(y_type))\nValueError: continuous is not supported\n\n  warnings.warn(\nEpoch 1/10\n922/922 - 7s - loss: 248949.3125 - accuracy: 0.0011 - 7s/epoch - 8ms/step\nEpoch 2/10\n922/922 - 4s - loss: 245018.9375 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 3/10\n922/922 - 4s - loss: 241847.3438 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 4/10\n922/922 - 4s - loss: 238931.2344 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 5/10\n922/922 - 4s - loss: 236148.3594 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 6/10\n922/922 - 4s - loss: 233445.6406 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 7/10\n922/922 - 4s - loss: 230797.9219 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 8/10\n922/922 - 4s - loss: 228192.2812 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 9/10\n922/922 - 4s - loss: 225621.8125 - accuracy: 0.0011 - 4s/epoch - 4ms/step\nEpoch 10/10\n922/922 - 4s - loss: 223082.5469 - accuracy: 0.0011 - 4s/epoch - 4ms/step\n10/10 [==============================] - 1s 2ms/step\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 219, in __call__\n    return self._score(\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 267, in _score\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n    raise ValueError(\"{0} is not supported\".format(y_type))\nValueError: continuous is not supported\n\n  warnings.warn(\nEpoch 1/10\n93/93 - 5s - loss: 259929.0781 - accuracy: 0.0011 - 5s/epoch - 51ms/step\nEpoch 2/10\n93/93 - 1s - loss: 259674.9375 - accuracy: 0.0011 - 510ms/epoch - 5ms/step\nEpoch 3/10\n93/93 - 1s - loss: 259371.7656 - accuracy: 0.0011 - 504ms/epoch - 5ms/step\nEpoch 4/10\n93/93 - 1s - loss: 258988.2031 - accuracy: 0.0011 - 586ms/epoch - 6ms/step\nEpoch 5/10\n93/93 - 1s - loss: 258536.7969 - accuracy: 0.0011 - 507ms/epoch - 5ms/step\nEpoch 6/10\n93/93 - 1s - loss: 258051.7656 - accuracy: 0.0011 - 571ms/epoch - 6ms/step\nEpoch 7/10\n93/93 - 1s - loss: 257558.7812 - accuracy: 0.0011 - 536ms/epoch - 6ms/step\nEpoch 8/10\n93/93 - 1s - loss: 257071.7500 - accuracy: 0.0011 - 569ms/epoch - 6ms/step\nEpoch 9/10\n93/93 - 1s - loss: 256596.8438 - accuracy: 0.0011 - 514ms/epoch - 6ms/step\nEpoch 10/10\n93/93 - 1s - loss: 256136.6719 - accuracy: 0.0011 - 572ms/epoch - 6ms/step\n10/10 [==============================] - 1s 8ms/step\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 219, in __call__\n    return self._score(\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 267, in _score\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n    raise ValueError(\"{0} is not supported\".format(y_type))\nValueError: continuous is not supported\n\n  warnings.warn(\nEpoch 1/10\n93/93 - 4s - loss: 262249.9688 - accuracy: 0.0011 - 4s/epoch - 47ms/step\nEpoch 2/10\n93/93 - 1s - loss: 261956.0312 - accuracy: 0.0011 - 520ms/epoch - 6ms/step\nEpoch 3/10\n93/93 - 1s - loss: 261589.6875 - accuracy: 0.0011 - 567ms/epoch - 6ms/step\nEpoch 4/10\n93/93 - 1s - loss: 261160.1406 - accuracy: 0.0011 - 511ms/epoch - 5ms/step\nEpoch 5/10\n93/93 - 1s - loss: 260694.8906 - accuracy: 0.0011 - 503ms/epoch - 5ms/step\nEpoch 6/10\n93/93 - 1s - loss: 260215.8594 - accuracy: 0.0011 - 502ms/epoch - 5ms/step\nEpoch 7/10\n93/93 - 1s - loss: 259736.6250 - accuracy: 0.0011 - 585ms/epoch - 6ms/step\nEpoch 8/10\n93/93 - 1s - loss: 259264.8281 - accuracy: 0.0011 - 507ms/epoch - 5ms/step\nEpoch 9/10\n93/93 - 1s - loss: 258804.4219 - accuracy: 0.0011 - 501ms/epoch - 5ms/step\nEpoch 10/10\n93/93 - 1s - loss: 258356.9062 - accuracy: 0.0011 - 577ms/epoch - 6ms/step\n10/10 [==============================] - 1s 1ms/step\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 219, in __call__\n    return self._score(\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 267, in _score\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n    raise ValueError(\"{0} is not supported\".format(y_type))\nValueError: continuous is not supported\n\n  warnings.warn(\nEpoch 1/10\n93/93 - 4s - loss: 255754.9688 - accuracy: 0.0011 - 4s/epoch - 47ms/step\nEpoch 2/10\n93/93 - 1s - loss: 255543.5000 - accuracy: 0.0011 - 515ms/epoch - 6ms/step\nEpoch 3/10\n93/93 - 1s - loss: 255259.5156 - accuracy: 0.0011 - 577ms/epoch - 6ms/step\nEpoch 4/10\n93/93 - 1s - loss: 254913.6719 - accuracy: 0.0011 - 524ms/epoch - 6ms/step\nEpoch 5/10\n93/93 - 1s - loss: 254528.6719 - accuracy: 0.0011 - 513ms/epoch - 6ms/step\nEpoch 6/10\n93/93 - 1s - loss: 254123.4375 - accuracy: 0.0011 - 568ms/epoch - 6ms/step\nEpoch 7/10\n93/93 - 1s - loss: 253710.3438 - accuracy: 0.0011 - 512ms/epoch - 6ms/step\nEpoch 8/10\n93/93 - 0s - loss: 253296.9688 - accuracy: 0.0011 - 499ms/epoch - 5ms/step\nEpoch 9/10\n93/93 - 1s - loss: 252887.8750 - accuracy: 0.0011 - 587ms/epoch - 6ms/step\nEpoch 10/10\n93/93 - 1s - loss: 252485.4219 - accuracy: 0.0011 - 515ms/epoch - 6ms/step\n10/10 [==============================] - 1s 8ms/step\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 219, in __call__\n    return self._score(\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 267, in _score\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n    raise ValueError(\"{0} is not supported\".format(y_type))\nValueError: continuous is not supported\n\n  warnings.warn(\nEpoch 1/10\n93/93 - 35s - loss: 252397.8906 - accuracy: 0.0011 - 35s/epoch - 381ms/step\nEpoch 2/10\n93/93 - 1s - loss: 252188.7031 - accuracy: 0.0011 - 585ms/epoch - 6ms/step\nEpoch 3/10\n93/93 - 1s - loss: 251915.7500 - accuracy: 0.0011 - 510ms/epoch - 5ms/step\nEpoch 4/10\n93/93 - 1s - loss: 251569.2344 - accuracy: 0.0011 - 587ms/epoch - 6ms/step\nEpoch 5/10\n93/93 - 1s - loss: 251165.1875 - accuracy: 0.0011 - 509ms/epoch - 5ms/step\nEpoch 6/10\n93/93 - 1s - loss: 250725.8125 - accuracy: 0.0011 - 580ms/epoch - 6ms/step\nEpoch 7/10\n93/93 - 1s - loss: 250269.8906 - accuracy: 0.0011 - 509ms/epoch - 5ms/step\nEpoch 8/10\n93/93 - 1s - loss: 249810.0625 - accuracy: 0.0011 - 592ms/epoch - 6ms/step\nEpoch 9/10\n93/93 - 1s - loss: 249354.1094 - accuracy: 0.0011 - 526ms/epoch - 6ms/step\nEpoch 10/10\n93/93 - 1s - loss: 248906.3281 - accuracy: 0.0011 - 574ms/epoch - 6ms/step\n10/10 [==============================] - 1s 8ms/step\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 219, in __call__\n    return self._score(\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 267, in _score\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n    raise ValueError(\"{0} is not supported\".format(y_type))\nValueError: continuous is not supported\n\n  warnings.warn(\nEpoch 1/10\n10/10 - 4s - loss: 260044.0469 - accuracy: 0.0011 - 4s/epoch - 410ms/step\nEpoch 2/10\n10/10 - 0s - loss: 260030.1562 - accuracy: 0.0011 - 21ms/epoch - 2ms/step\nEpoch 3/10\n10/10 - 0s - loss: 260016.5312 - accuracy: 0.0011 - 95ms/epoch - 10ms/step\nEpoch 4/10\n10/10 - 0s - loss: 260002.7969 - accuracy: 0.0011 - 89ms/epoch - 9ms/step\nEpoch 5/10\n10/10 - 0s - loss: 259988.9062 - accuracy: 0.0011 - 91ms/epoch - 9ms/step\nEpoch 6/10\n10/10 - 0s - loss: 259974.7344 - accuracy: 0.0011 - 26ms/epoch - 3ms/step\nEpoch 7/10\n10/10 - 0s - loss: 259960.2031 - accuracy: 0.0011 - 80ms/epoch - 8ms/step\nEpoch 8/10\n10/10 - 0s - loss: 259945.2656 - accuracy: 0.0011 - 89ms/epoch - 9ms/step\nEpoch 9/10\n10/10 - 0s - loss: 259929.7344 - accuracy: 0.0011 - 95ms/epoch - 10ms/step\nEpoch 10/10\n10/10 - 0s - loss: 259913.5938 - accuracy: 0.0011 - 21ms/epoch - 2ms/step\n10/10 [==============================] - 1s 8ms/step\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 219, in __call__\n    return self._score(\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 267, in _score\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n    raise ValueError(\"{0} is not supported\".format(y_type))\nValueError: continuous is not supported\n\n  warnings.warn(\nEpoch 1/10\n10/10 - 4s - loss: 262453.5000 - accuracy: 0.0011 - 4s/epoch - 390ms/step\nEpoch 2/10\n10/10 - 0s - loss: 262430.9688 - accuracy: 0.0011 - 87ms/epoch - 9ms/step\nEpoch 3/10\n10/10 - 0s - loss: 262408.9375 - accuracy: 0.0011 - 21ms/epoch - 2ms/step\nEpoch 4/10\n10/10 - 0s - loss: 262386.9375 - accuracy: 0.0011 - 90ms/epoch - 9ms/step\nEpoch 5/10\n10/10 - 0s - loss: 262364.9375 - accuracy: 0.0011 - 93ms/epoch - 9ms/step\nEpoch 6/10\n10/10 - 0s - loss: 262342.8438 - accuracy: 0.0011 - 88ms/epoch - 9ms/step\nEpoch 7/10\n10/10 - 0s - loss: 262320.5625 - accuracy: 0.0011 - 22ms/epoch - 2ms/step\nEpoch 8/10\n10/10 - 0s - loss: 262298.0312 - accuracy: 0.0011 - 90ms/epoch - 9ms/step\nEpoch 9/10\n10/10 - 0s - loss: 262275.1875 - accuracy: 0.0011 - 89ms/epoch - 9ms/step\nEpoch 10/10\n10/10 - 0s - loss: 262252.0312 - accuracy: 0.0011 - 86ms/epoch - 9ms/step\n10/10 [==============================] - 1s 1ms/step\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 219, in __call__\n    return self._score(\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 267, in _score\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n    raise ValueError(\nValueError: Classification metrics can't handle a mix of continuous and binary targets\n\n  warnings.warn(\nEpoch 1/10\n10/10 - 4s - loss: 255831.3281 - accuracy: 0.0011 - 4s/epoch - 378ms/step\nEpoch 2/10\n10/10 - 0s - loss: 255816.6875 - accuracy: 0.0011 - 24ms/epoch - 2ms/step\nEpoch 3/10\n10/10 - 0s - loss: 255802.0938 - accuracy: 0.0011 - 83ms/epoch - 8ms/step\nEpoch 4/10\n10/10 - 0s - loss: 255787.2031 - accuracy: 0.0011 - 90ms/epoch - 9ms/step\nEpoch 5/10\n10/10 - 0s - loss: 255771.8125 - accuracy: 0.0011 - 89ms/epoch - 9ms/step\nEpoch 6/10\n10/10 - 0s - loss: 255755.8906 - accuracy: 0.0011 - 24ms/epoch - 2ms/step\nEpoch 7/10\n10/10 - 0s - loss: 255739.3594 - accuracy: 0.0011 - 92ms/epoch - 9ms/step\nEpoch 8/10\n10/10 - 0s - loss: 255722.2188 - accuracy: 0.0011 - 85ms/epoch - 9ms/step\nEpoch 9/10\n10/10 - 0s - loss: 255704.3281 - accuracy: 0.0011 - 92ms/epoch - 9ms/step\nEpoch 10/10\n10/10 - 0s - loss: 255685.6875 - accuracy: 0.0011 - 21ms/epoch - 2ms/step\n10/10 [==============================] - 1s 3ms/step\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 219, in __call__\n    return self._score(\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 267, in _score\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n    raise ValueError(\nValueError: Classification metrics can't handle a mix of continuous and binary targets\n\n  warnings.warn(\nEpoch 1/10\n10/10 - 4s - loss: 252519.8125 - accuracy: 0.0011 - 4s/epoch - 390ms/step\nEpoch 2/10\n10/10 - 0s - loss: 252505.1094 - accuracy: 0.0011 - 26ms/epoch - 3ms/step\nEpoch 3/10\n10/10 - 0s - loss: 252490.4531 - accuracy: 0.0011 - 88ms/epoch - 9ms/step\nEpoch 4/10\n10/10 - 0s - loss: 252475.4688 - accuracy: 0.0011 - 82ms/epoch - 8ms/step\nEpoch 5/10\n10/10 - 0s - loss: 252460.1094 - accuracy: 0.0011 - 93ms/epoch - 9ms/step\nEpoch 6/10\n10/10 - 0s - loss: 252444.2656 - accuracy: 0.0011 - 91ms/epoch - 9ms/step\nEpoch 7/10\n10/10 - 0s - loss: 252427.9062 - accuracy: 0.0011 - 31ms/epoch - 3ms/step\nEpoch 8/10\n10/10 - 0s - loss: 252410.9688 - accuracy: 0.0011 - 83ms/epoch - 8ms/step\nEpoch 9/10\n10/10 - 0s - loss: 252393.3594 - accuracy: 0.0011 - 85ms/epoch - 9ms/step\nEpoch 10/10\n10/10 - 0s - loss: 252375.1250 - accuracy: 0.0011 - 88ms/epoch - 9ms/step\n10/10 [==============================] - 1s 8ms/step\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 219, in __call__\n    return self._score(\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 267, in _score\n    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n    raise ValueError(\nValueError: Classification metrics can't handle a mix of continuous and binary targets\n\n  warnings.warn(\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [nan nan nan]\n  warnings.warn(\nEpoch 1/10\n1229/1229 - 8s - loss: 448304.9062 - accuracy: 8.1367e-04 - 8s/epoch - 7ms/step\nEpoch 2/10\n1229/1229 - 5s - loss: 441924.4375 - accuracy: 8.1367e-04 - 5s/epoch - 4ms/step\nEpoch 3/10\n1229/1229 - 6s - loss: 436675.6562 - accuracy: 8.1367e-04 - 6s/epoch - 5ms/step\nEpoch 4/10\n1229/1229 - 6s - loss: 431693.7500 - accuracy: 8.1367e-04 - 6s/epoch - 5ms/step\nEpoch 5/10\n1229/1229 - 6s - loss: 426838.5938 - accuracy: 8.1367e-04 - 6s/epoch - 4ms/step\nEpoch 6/10\n1229/1229 - 5s - loss: 422064.6250 - accuracy: 8.1367e-04 - 5s/epoch - 4ms/step\nEpoch 7/10\n1229/1229 - 5s - loss: 417352.8750 - accuracy: 8.1367e-04 - 5s/epoch - 4ms/step\nEpoch 8/10\n1229/1229 - 5s - loss: 412695.0312 - accuracy: 8.1367e-04 - 5s/epoch - 4ms/step\nEpoch 9/10\n1229/1229 - 5s - loss: 408087.5312 - accuracy: 8.1367e-04 - 5s/epoch - 4ms/step\nEpoch 10/10\n1229/1229 - 5s - loss: 403527.5938 - accuracy: 8.1367e-04 - 5s/epoch - 4ms/step\n","output_type":"stream"}],"execution_count":81},{"cell_type":"code","source":"print(\"best parameters are:\", grid_search_fit.best_params_)","metadata":{"tags":[],"cell_id":"ff2a73e4a80a43448eeba0ce08187e9a","source_hash":"1b3dbb7d","execution_start":1670973538227,"execution_millis":9,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"best parameters are: {'batch_size': 1}\n","output_type":"stream"}],"execution_count":82},{"cell_type":"code","source":"","metadata":{"tags":[],"cell_id":"335035c4f0ec4fac81f9de4bee739254","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=fd4d66f4-9d7c-4cde-9a98-160e4af16392' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"3118f98a875042408245d71b3994389f","deepnote_execution_queue":[]}}